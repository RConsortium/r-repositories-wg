\input texinfo
@c %**start of header
@setfilename URL_checks.info
@settitle CRAN URL checks
@documentlanguage en

@titlepage
@title CRAN URL checks
@author CRAN Repository Maintainers
@end titlepage

The CRAN submission checks run by @command{R CMD check --as-cran} check
the availability of URLs in files including @file{DESCRIPTION},
@file{CITATION}, @file{NEWS.Rd}, @file{NEWS.md}, @file{README.md}, and
the @file{.Rd} help pages and HTML files in @file{inst/doc}.  These
notes explain the checks.

They are only done if the build of R in use supports a suitably recent
version of @code{libcurl}: most should.

@itemize

@item
@code{\url} markup should only be used for always-active URLs.  Examples
of the use of e.g.@: @code{localhost} should use @code{\samp} markup.

@item
The checks done are equivalent to using @code{curl -I -L} on the command
line (where @command{curl} is available).  They may give different results
from accessing the URL in your browser.  Possible reasons include:

@itemize

@item
Some websites do not allow @samp{HEAD} requests.  That should be
reported with a @code{405} status value, and such sites are not reported
in the checks.  But some are mis-configured, notably
@samp{http://www.sciencedirect.com} (which is special-cased in the checks).

@item
It is possible that a site relies on cookies you have saved in your
browser or is insecure and you have saved an exception.  Try a vanilla
browser session, another browser or even another machine.

@item
If there are issues with verifying the identity of the site, the checks
will report if the site is accessible without verification.  The checks
use the root certificates which @code{libcurl} was compiled to use: on
most systems these are from the OS (by default on Windows those shipped
with the @code{libcurl} binaries are used).  Browsers may use the OS
versions, or may use their own copies which can explain discrepancies.

@item
HTTP sites reporting status codes @code{403} and @code{503} may work in
a browser, although most do not. This has even been seen for status code
@code{404}.
@end itemize

If you find one of the exceptions, explain your findings in the submission.

@item
There may be sites which are available to some users but not to all, so
may work for you but not the CRAN maintainers.  Such sites are best
avoided, but may be used in a @file{.Rd} file provided this is explained
in the file and in the submission.

@item
A surprisingly large number of websites use redirection and the issues
may apply to a site redirected to.  You can see the redirection
history using @code{curlGetHeaders("http://www.mywebsite.org/")}.  Where
redirection is permanent you should use the redirected URL (see
@url{https://tools.ietf.org/html/rfc7231#section-6.4.2, RFC 7231}).

One common issue is the redirection of @code{http://} URLs to
@code{https://} URLs, or even @emph{vice versa}. 

@item
The timeout allowed for making a connection to a site is 60 seconds.
This is normally more than adequate and avoids long delays for sites
which will never respond.  But sometimes the DNS lookup for a
rarely-used site on a slow network takes longer than that, so if a site
is not resolved it is worth re-trying 15 minutes later.

@end itemize

@bye
